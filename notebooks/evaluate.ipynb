{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dac670",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53af78",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeebb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e2694",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e98e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = pathlib.Path(\n",
    "    #\"/media/cicheck/Extreme Pro/models/base/best_base_meso_net_05_0.14.h5\"\n",
    "    \"/media/cicheck/Extreme Pro/models/old/base_new_new/best_base_meso_net_05_0.16.h5\"\n",
    ")\n",
    "DATASET_PATH = pathlib.Path(\"/media/cicheck/Extreme Pro/datasets/modified/mod_1\")\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30940214",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f064160",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_pattern = re.compile(r\"(?P<metric_prefix>\\w+)((?P<metric_number>_\\d+))?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87edb48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auc_1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_pattern.match(\"auc_1\").group(\"metric_prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a8fade4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1670218073.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_2805/1670218073.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    else 2: 2\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{\n",
    "    1: 1\n",
    "    if a == 1\n",
    "    else 2: 2\n",
    "    for a in (1, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d42a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_metric_names_to_rephrased_names = {\n",
    "    \"binary_accuracy\": \"accuracy\",\n",
    "    \"auc\": \"AUC\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"true_positives\": \"TP\",\n",
    "    \"true_negatives\": \"TN\",\n",
    "    \"false_positives\": \"FP\",\n",
    "    \"false_negatives\": \"FN\",\n",
    "}\n",
    "\n",
    "def _rephrase_metrics_dict(metrics_dict: dict[str, float]) -> dict[str, float]:\n",
    "    # Remove sufixes, e.g. auc_3 -> auc\n",
    "    prefix_pattern = re.compile(r\"(?P<metric_prefix>\\w+)_(?P<metric_number>\\d+)\")\n",
    "    # TODO: ugly comperhension\n",
    "    normalized_metrics_dict = {\n",
    "        (prefix_pattern.match(metric).group(\"metric_prefix\") if prefix_pattern.match(metric) else metric): value\n",
    "        for metric, value in metrics_dict.items()\n",
    "    }\n",
    "    return {\n",
    "        (_metric_names_to_rephrased_names[metric] if metric in _metric_names_to_rephrased_names else metric): value\n",
    "        for metric, value in metrics_dict.items()\n",
    "    }\n",
    "\n",
    "def _build_single_row(*columns, width):\n",
    "    row_as_string = \"|\"\n",
    "    for column in columns:\n",
    "        row_as_string += column.ljust(width, \" \")\n",
    "        row_as_string += \"|\"\n",
    "    row_as_string +=\"\\n\"\n",
    "    return row_as_string\n",
    "\n",
    "def print_metrics_dict_as_table(\n",
    "    metrics_dict: dict[str, float], width: int = 30, precision: int = 5\n",
    "):\n",
    "    \"\"\"Print metrics dictionay as markdown table.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: metrics dictionay (i.e. output of keras evaluate which output type set to dict).\n",
    "        width: width of \n",
    "    \"\"\"\n",
    "    first_column_name = \" metrics\"\n",
    "    second_column_name = \" values\"\n",
    "    table_as_string = \"\"\n",
    "    table_as_string += _build_single_row(first_column_name, second_column_name, width=width)\n",
    "    header_sign = \":---:\"\n",
    "    table_as_string += _build_single_row(header_sign, header_sign, width=width)\n",
    "    rephrased_metric_dict = _rephrase_metrics_dict(metrics_dict)\n",
    "    for metric, value in rephrased_metric_dict.items():\n",
    "        table_as_string += _build_single_row(metric, \"{:.2f}\".format(value), width=width)\n",
    "    print(table_as_string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc9554fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| metrics                      | values                       |\n",
      "|:---:                         |:---:                         |\n",
      "|loss                          |0.18                          |\n",
      "|accuracy                      |0.95                          |\n",
      "|auc_3                         |0.94                          |\n",
      "|precision_3                   |0.73                          |\n",
      "|recall_3                      |0.73                          |\n",
      "|true_positives_3              |33441.00                      |\n",
      "|true_negatives_3              |410275.00                     |\n",
      "|false_positives_3             |12264.00                      |\n",
      "|false_negatives_3             |12684.00                      |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_metrics_dict_as_table(metrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f839e49c",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5d5c038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluated_model = models.load_model(MODEL_PATH, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19313fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "        metrics.BinaryAccuracy(),\n",
    "        metrics.AUC(),\n",
    "        metrics.Precision(),\n",
    "        metrics.Recall(),\n",
    "        metrics.TruePositives(),\n",
    "        metrics.TrueNegatives(),\n",
    "        metrics.FalsePositives(),\n",
    "        metrics.FalseNegatives(),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9306a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model needs to be compiled again to set targeted metrices\n",
    "optimizer = optimizers.Adam(\n",
    "    learning_rate=1e-3,\n",
    "    epsilon=1e-08\n",
    ")\n",
    "\n",
    "evaluated_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d87817",
   "metadata": {},
   "source": [
    "## Evaluate whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d2c4ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468664 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "evaluation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH.joinpath(\"test\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode=\"binary\",\n",
    "    class_names=[\"fakes\", \"reals\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d77fbd70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14646/14646 [==============================] - 496s 34ms/step - loss: 0.1848 - binary_accuracy: 0.9468 - auc_3: 0.9351 - precision_3: 0.7317 - recall_3: 0.7250 - true_positives_3: 33441.0000 - true_negatives_3: 410275.0000 - false_positives_3: 12264.0000 - false_negatives_3: 12684.0000\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = evaluated_model.evaluate(evaluation_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "612757b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.18484479188919067,\n",
       " 'binary_accuracy': 0.9467678070068359,\n",
       " 'auc_3': 0.9351059198379517,\n",
       " 'precision_3': 0.7316704988479614,\n",
       " 'recall_3': 0.7250081300735474,\n",
       " 'true_positives_3': 33441.0,\n",
       " 'true_negatives_3': 410275.0,\n",
       " 'false_positives_3': 12264.0,\n",
       " 'false_negatives_3': 12684.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b88f352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.15903404355049133,\n",
       " 'binary_accuracy': 0.948237955570221,\n",
       " 'auc_2': 0.9506139755249023,\n",
       " 'precision_2': 0.7356554865837097,\n",
       " 'recall_2': 0.7399458289146423,\n",
       " 'true_positives_2': 34130.0,\n",
       " 'true_negatives_2': 410275.0,\n",
       " 'false_positives_2': 12264.0,\n",
       " 'false_negatives_2': 11995.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a315f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fajnie było widać że jedyne co się zmieniło to niektóre true positives przeszły na false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f54d91",
   "metadata": {},
   "source": [
    "## Evaluate single modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87909e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_name = \n",
    "mod_dir_path = DATASET_PATH / \"test\" / \"reals\" / mod_name\n",
    "no_mod_images = len(list(mod_dir_path.iterdir()))\n",
    "no_mod_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672ebdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495495d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifications_ds =  tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    DATASET_PATH.joinpath(f\"test/reals/{mod_name}\"),\n",
    "    labels=(0 for _ in range(no_mod_images))\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d0d0a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "tf.Tensor(\n",
      "[[[194.99023  201.99023  215.99023 ]\n",
      "  [194.98042  201.98042  215.96872 ]\n",
      "  [193.96875  200.96875  212.97266 ]\n",
      "  ...\n",
      "  [223.97069  229.8828   248.86327 ]\n",
      "  [229.9629   235.9629   254.9629  ]\n",
      "  [224.01172  238.99414  255.      ]]\n",
      "\n",
      " [[189.97263  196.97263  210.97263 ]\n",
      "  [187.93549  194.93549  208.93549 ]\n",
      "  [182.94336  189.94336  203.94336 ]\n",
      "  ...\n",
      "  [223.96094  229.87305  248.85352 ]\n",
      "  [228.9707   234.9707   253.9707  ]\n",
      "  [224.00977  238.99219  254.99805 ]]\n",
      "\n",
      " [[185.89456  192.8848   206.9141  ]\n",
      "  [181.88148  188.87172  202.90114 ]\n",
      "  [175.01944  182.00967  196.0585  ]\n",
      "  ...\n",
      "  [223.92178  229.8339   248.81436 ]\n",
      "  [228.92194  234.92194  253.92194 ]\n",
      "  [223.96094  238.94336  254.94922 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 45.9883    43.9883    39.9883  ]\n",
      "  [ 45.        43.        39.      ]\n",
      "  [ 45.        43.        39.      ]\n",
      "  ...\n",
      "  [ 55.00019   55.00019   55.00019 ]\n",
      "  [ 54.015568  54.015568  54.015568]\n",
      "  [ 54.009766  54.009766  54.009766]]\n",
      "\n",
      " [[ 45.003906  45.98633   38.009766]\n",
      "  [ 44.011684  44.97663   37.02337 ]\n",
      "  [ 45.        43.        39.      ]\n",
      "  ...\n",
      "  [ 54.015568  54.015568  54.015568]\n",
      "  [ 54.000034  54.000034  54.000034]\n",
      "  [ 54.        54.        54.      ]]\n",
      "\n",
      " [[ 44.998047  45.998047  37.998047]\n",
      "  [ 44.00586   44.98828   37.01172 ]\n",
      "  [ 45.        43.        39.      ]\n",
      "  ...\n",
      "  [ 54.009766  54.009766  54.009766]\n",
      "  [ 53.0078    53.0078    53.0078  ]\n",
      "  [ 53.001953  53.001953  53.001953]]], shape=(256, 256, 3), dtype=float32)\n",
      "XDDDDDD\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in evaluation_dataset:\n",
    "    print(x[0].shape)\n",
    "    print(x[0])\n",
    "    print(\"XDDDDDD\")\n",
    "    print(y[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64aef640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'args_0:0' shape=(None, 256, 256, 3) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1345b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ehh = evaluation_dataset.filter(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28b01685",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8629d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator.flow_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = next(img_gen.flow_from_directory(DATASET_PATH.joinpath(\"reals\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfa73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
